{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6ba2d28",
   "metadata": {},
   "source": [
    "# Libraries used\n",
    "\n",
    "Running Kernel3.9.13 base anaconda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a47ff5b1",
   "metadata": {},
   "source": [
    "pip install squarify\n",
    "pip install yellowbrick\n",
    "pip install plotly\n",
    "pip install seaborn\n",
    "pip install lazypredict\n",
    "pip install pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e469ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "#import squarify #treemap\n",
    "import os\n",
    "import matplotlib\n",
    "import warnings\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "#to enable the inline plotting\n",
    "%matplotlib inline \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3cc5995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#rfc using regularization and gridsearch to find the best parameters for the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from yellowbrick.style.palettes import PALETTES, SEQUENCES, color_palette\n",
    "\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf1b672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for EDA. Using the display() function to have  well-formatted tables. We are mainly using pandas to explore the datasets\n",
    "\n",
    "def dataset_description(df_target):\n",
    "\n",
    "    print('This is the Dataset shape: %s\\n' % (df_target.shape, ))\n",
    "    print('Dataset columns: %s\\n' % df_target.columns)\n",
    "\n",
    "    print('\\nColumns description:\\n')\n",
    "    display(df_target.info())\n",
    "    display(df_target.describe())  # describe the dataset\n",
    "\n",
    "    print('\\nNull values:\\n')\n",
    "    display(df_target.isnull().sum())  # Identify null values\n",
    "\n",
    "#function performing a quick check on df_inspection to have best of pandas functions separated by a line\n",
    "def quick_check(dataframe):\n",
    "    print('First 5 rows %s\\n')\n",
    "    print(dataframe.head(2))\n",
    "    print(\"=====================================\")\n",
    "    print('Dataframe shape %s\\n')\n",
    "    print(dataframe.shape)\n",
    "    print(\"=====================================\")\n",
    "    print('Dataframe describe categorical %s\\n')\n",
    "    print(dataframe.describe(include=['O']))\n",
    "    print(\"=====================================\")\n",
    "    print('Dataframe null values %s\\n')\n",
    "    print(dataframe.isnull().sum())\n",
    "    print(\"=====================================\")\n",
    "    print('Dataframe value counts %s\\n')\n",
    "    print(dataframe.value_counts())\n",
    "    print(\"=====================================\")\n",
    "\n",
    "#stats function\n",
    "def stats(dataframe):\n",
    "    print('Dataframe correlation %s\\n')\n",
    "    print(dataframe.corr())\n",
    "    print(\"=====================================\")\n",
    "    print('Dataframe covariance %s\\n')\n",
    "    print(dataframe.cov())\n",
    "    print(\"=====================================\")\n",
    "    print('Dataframe skew %s\\n')\n",
    "    print(dataframe.skew())\n",
    "    print(\"=====================================\")\n",
    "    print('Dataframe kurtosis %s\\n')\n",
    "    print(dataframe.kurt())\n",
    "    print(\"=====================================\")\n",
    "\n",
    "#create a function to normalize characters from a dataset's column in Spanish\n",
    "def normalize_characters(df, column):\n",
    "    df[column] = df[column].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    df[column] = df[column].str.lower()\n",
    "    df[column] = df[column].str.replace('á', 'a')\n",
    "    df[column] = df[column].str.replace('é', 'e')\n",
    "    df[column] = df[column].str.replace('í', 'i')\n",
    "    df[column] = df[column].str.replace('ó', 'o')\n",
    "    df[column] = df[column].str.replace('ú', 'u')\n",
    "    df[column] = df[column].str.replace('ñ', 'n')\n",
    "    df[column] = df[column].str.replace('ü', 'u')\n",
    "    df[column] = df[column].str.replace('ç', 'c')\n",
    "    df[column] = df[column].str.replace('(', '')\n",
    "    df[column] = df[column].str.replace(')', '')\n",
    "    df[column] = df[column].str.replace('\\'', '')\n",
    "    df[column] = df[column].str.replace('´', '')\n",
    "    df[column] = df[column].str.replace('`', '')\n",
    "    df[column] = df[column].str.replace('’', '')\n",
    "    return df.head(2)\n",
    "\n",
    "#create function to change detypes in64 to int32 in a df\n",
    "def change_dtypes(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'int64':\n",
    "            df[col] = df[col].astype('int32')\n",
    "        elif df[col].dtype == 'float64':\n",
    "            df[col] = df[col].astype('float32')\n",
    "    return df\n",
    "\n",
    "def outlier_function(df, col_name):\n",
    "    \"\"\" this function detects first and third quartile and interquartile range for a given column of a dataframe\n",
    "    then calculates upper and lower limits to determine outliers conservatively\n",
    "    returns the number of lower and uper limit and number of outliers respectively\"\"\"\n",
    "    first_quartile = np.percentile(np.array(df[col_name].tolist()), 25)\n",
    "    third_quartile = np.percentile(np.array(df[col_name].tolist()), 75)\n",
    "    IQR = third_quartile - first_quartile\n",
    "                        \n",
    "    upper_limit = third_quartile+(3*IQR)\n",
    "    lower_limit = first_quartile-(3*IQR)\n",
    "    outlier_count = 0\n",
    "                    \n",
    "    for value in df[col_name].tolist():\n",
    "        if (value < lower_limit) | (value > upper_limit):\n",
    "            outlier_count +=1\n",
    "        else:\n",
    "            pass\n",
    "    return lower_limit, upper_limit, outlier_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e28e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show all print outputs when using a function\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#display all columns\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebce254",
   "metadata": {},
   "source": [
    "# Importing previous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dad7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#point to the folder where the data is stored\n",
    "os.chdir(r\"C:\\Users\\pedro\\datathon\")\n",
    "\n",
    "# Loading combined_mod dataset\n",
    "train_consolidated = pd.read_csv('df_baseline.csv')\n",
    "sample_submission = pd.read_csv('submission_sample_prepared2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dae7144",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_consolidated = train_consolidated[sample_submission.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input null values in sample_submission with mean of the column\n",
    "sample_submission['Yearly Sun Hours (hours)'] = sample_submission['Yearly Sun Hours (hours)'].fillna(sample_submission['Yearly Sun Hours (hours)'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0265315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_consolidated.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fffff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a subset for altering the dataset after initial EDA\n",
    "df_baseline = train_consolidated.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86211d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count values for Incidence\n",
    "df_baseline['Incidence'].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a4bc545",
   "metadata": {},
   "source": [
    "# PCA approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2cbcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform pca on df_baseline and split the data into train and test 80 20stratifying by the target variable Incidence stratify=y\n",
    "pca = PCA(n_components=1000, random_state=42)\n",
    "X = df_baseline.drop(['Incidence'], axis=1)\n",
    "y = df_baseline['Incidence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b4a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d054e766",
   "metadata": {},
   "source": [
    "# Trying model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfc model on pca data performing cross validation and kfold with 5 splits over a list of parameters\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train_pca, y_train)\n",
    "CV_rfc.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73537823",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test_pca)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648b9d4",
   "metadata": {},
   "source": [
    "#rfc model on pca data and classification report to evaluate the model performance on the test set \n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42, verbose=1, n_jobs=-1, max_depth=2) \n",
    "rfc.fit(X_train_pca, y_train)\n",
    "y_pred = rfc.predict(X_test_pca)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use rfc model to predict probabilites on pca test\n",
    "y_pred_proba = rfc.predict_proba(X_test_pca)[:,1]\n",
    "y_pred_proba\n",
    "\n",
    "#plot roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='RFC')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('RFC ROC Curve')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d820883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop incidence in sample_submission\n",
    "sample_submission = sample_submission.drop('Incidence', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ed3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use rfc model to predict probabilites on sample_submission converting it first to pca with 2 components random_state=42\n",
    "sample_submission_pca = pca.transform(sample_submission)\n",
    "y_pred_proba = rfc.predict_proba(sample_submission_pca)[:,1]\n",
    "y_pred_proba\n",
    "\n",
    "#add the predicted probabilities to the sample_submission dataframe\n",
    "sample_submission['Incidence'] = y_pred_proba\n",
    "sample_submission.head(1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc714c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all columns except PipeId and Incidence in submission2 creating kaggle_submission\n",
    "kaggle_submission = sample_submission.drop(['Diameter', 'Length', 'Pressure', 'NumConnections', 'aspect',\n",
    "       'Relative_Thickness', 'area_connection', 'gas_natural',\n",
    "       'Material_Acrylonitrile-Butadiene-Styrene', 'Material_Copper',\n",
    "       'Material_Fiberglass-Reinforced Plastic', 'Material_Polyethylene',\n",
    "       'Material_Polypropylene', 'Yearly Sun Hours (hours)',\n",
    "       'Average_MonthsLastRev', 'MonthsLastRev', 'No_Inspections',\n",
    "       'No_Incidences_Total', 'Age_pipe_at_inspection',\n",
    "       'Population density (persons/sqkm)'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22deedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b2a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea0d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export kaggle_submission to csv\n",
    "os.chdir(r\"C:\\Users\\pedro\\datathon\")\n",
    "\n",
    "kaggle_submission.to_csv('kaggle_submission_new_features_pca1000_rfcv.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "326e4f63ad54c217260fc7be1c53acea6ef3ea6cd7ac93b3b02195c6d8fa7cb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
