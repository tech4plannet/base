{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6ba2d28",
   "metadata": {},
   "source": [
    "# Libraries used\n",
    "\n",
    "Running Kernel3.9.13 base anaconda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a47ff5b1",
   "metadata": {},
   "source": [
    "pip install squarify\n",
    "pip install yellowbrick\n",
    "pip install plotly\n",
    "pip install seaborn\n",
    "pip install lazypredict\n",
    "pip install pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e469ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "import os\n",
    "import matplotlib\n",
    "import warnings\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "#to enable the inline plotting\n",
    "%matplotlib inline \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cc5995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#rfc using regularization and gridsearch to find the best parameters for the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from yellowbrick.style.palettes import PALETTES, SEQUENCES, color_palette\n",
    "\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1b672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for EDA. Using the display() function to have  well-formatted tables. We are mainly using pandas to explore the datasets\n",
    "\n",
    "def dataset_description(df_target):\n",
    "\n",
    "    print('This is the Dataset shape: %s\\n' % (df_target.shape, ))\n",
    "    print('Dataset columns: %s\\n' % df_target.columns)\n",
    "\n",
    "    print('\\nColumns description:\\n')\n",
    "    display(df_target.info())\n",
    "    display(df_target.describe())  # describe the dataset\n",
    "\n",
    "    print('\\nNull values:\\n')\n",
    "    display(df_target.isnull().sum())  # Identify null values\n",
    "\n",
    "#function performing a quick check on df_inspection to have best of pandas functions separated by a line\n",
    "def quick_check(dataframe):\n",
    "    print('First 5 rows %s\\n')\n",
    "    print(dataframe.head(2))\n",
    "    print(\"=====================================\")\n",
    "    print('Dataframe shape %s\\n')\n",
    "    print(dataframe.shape)\n",
    "    print(\"=====================================\")\n",
    "    print('Dataframe describe categorical %s\\n')\n",
    "    print(dataframe.describe(include=['O']))\n",
    "    print(\"=====================================\")\n",
    "    print('Dataframe null values %s\\n')\n",
    "    print(dataframe.isnull().sum())\n",
    "    print(\"=====================================\")\n",
    "    print('Dataframe value counts %s\\n')\n",
    "    print(dataframe.value_counts())\n",
    "    print(\"=====================================\")\n",
    "\n",
    "#stats function\n",
    "def stats(dataframe):\n",
    "    print('Dataframe correlation %s\\n')\n",
    "    print(dataframe.corr())\n",
    "    print(\"=====================================\")\n",
    "    print('Dataframe covariance %s\\n')\n",
    "    print(dataframe.cov())\n",
    "    print(\"=====================================\")\n",
    "    print('Dataframe skew %s\\n')\n",
    "    print(dataframe.skew())\n",
    "    print(\"=====================================\")\n",
    "    print('Dataframe kurtosis %s\\n')\n",
    "    print(dataframe.kurt())\n",
    "    print(\"=====================================\")\n",
    "\n",
    "#create a function to normalize characters from a dataset's column in Spanish\n",
    "def normalize_characters(df, column):\n",
    "    df[column] = df[column].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    df[column] = df[column].str.lower()\n",
    "    df[column] = df[column].str.replace('á', 'a')\n",
    "    df[column] = df[column].str.replace('é', 'e')\n",
    "    df[column] = df[column].str.replace('í', 'i')\n",
    "    df[column] = df[column].str.replace('ó', 'o')\n",
    "    df[column] = df[column].str.replace('ú', 'u')\n",
    "    df[column] = df[column].str.replace('ñ', 'n')\n",
    "    df[column] = df[column].str.replace('ü', 'u')\n",
    "    df[column] = df[column].str.replace('ç', 'c')\n",
    "    df[column] = df[column].str.replace('(', '')\n",
    "    df[column] = df[column].str.replace(')', '')\n",
    "    df[column] = df[column].str.replace('\\'', '')\n",
    "    df[column] = df[column].str.replace('´', '')\n",
    "    df[column] = df[column].str.replace('`', '')\n",
    "    df[column] = df[column].str.replace('’', '')\n",
    "    return df.head(2)\n",
    "\n",
    "#create function to change detypes in64 to int32 in a df\n",
    "def change_dtypes(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'int64':\n",
    "            df[col] = df[col].astype('int32')\n",
    "        elif df[col].dtype == 'float64':\n",
    "            df[col] = df[col].astype('float32')\n",
    "    return df\n",
    "\n",
    "def outlier_function(df, col_name):\n",
    "    \"\"\" this function detects first and third quartile and interquartile range for a given column of a dataframe\n",
    "    then calculates upper and lower limits to determine outliers conservatively\n",
    "    returns the number of lower and uper limit and number of outliers respectively\"\"\"\n",
    "    first_quartile = np.percentile(np.array(df[col_name].tolist()), 25)\n",
    "    third_quartile = np.percentile(np.array(df[col_name].tolist()), 75)\n",
    "    IQR = third_quartile - first_quartile\n",
    "                        \n",
    "    upper_limit = third_quartile+(3*IQR)\n",
    "    lower_limit = first_quartile-(3*IQR)\n",
    "    outlier_count = 0\n",
    "                    \n",
    "    for value in df[col_name].tolist():\n",
    "        if (value < lower_limit) | (value > upper_limit):\n",
    "            outlier_count +=1\n",
    "        else:\n",
    "            pass\n",
    "    return lower_limit, upper_limit, outlier_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e28e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show all print outputs when using a function\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#display all columns\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebce254",
   "metadata": {},
   "source": [
    "# Importing previous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#point to the folder where the data is stored\n",
    "os.chdir(r\"C:\\Users\\JuanHorrillo\\OneDrive - IE Students\\Documents\\Masters\\Sustainability\\csvs\")\n",
    "\n",
    "# Loading combined_mod dataset\n",
    "train_consolidated = pd.read_csv('df_baseline.csv')\n",
    "sample_submission = pd.read_csv('submission_sample_prepared2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1043f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_consolidated = train_consolidated[sample_submission.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b43b0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input null values in sample_submission with mean of the column\n",
    "sample_submission['Yearly Sun Hours (hours)'] = sample_submission['Yearly Sun Hours (hours)'].fillna(sample_submission['Yearly Sun Hours (hours)'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02933a92",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "#pandas profiling report for train_consolidated exporting a file\n",
    "profile = ProfileReport(train_consolidated, title='Pandas Profiling Report', explorative=True)\n",
    "profile.to_file(\"train_consolidated.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dae7144",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_consolidated.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fffff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a subset for altering the dataset after initial EDA\n",
    "df_baseline = train_consolidated.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86211d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count values for Incidence\n",
    "df_baseline['Incidence'].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d961fba7",
   "metadata": {},
   "source": [
    "# Stratifying with undersampling MAYBE WE SHOULD TRY THIS LATER!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0d1e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersampling the dataset\n",
    "df_baseline_undersampling = df_baseline.groupby('Incidence').apply(lambda x: x.sample(df_baseline['Incidence'].value_counts().min(), random_state=42)).reset_index(drop=True)\n",
    "df_baseline_undersampling['Incidence'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae26f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_baseline_undersampling.drop('Incidence', axis=1)\n",
    "y = df_baseline_undersampling['Incidence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4486a1",
   "metadata": {},
   "source": [
    "## Stratified Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d1c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_baseline.drop(['Incidence'], axis=1)\n",
    "y = df_baseline['Incidence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf1abca0",
   "metadata": {},
   "source": [
    "# SMOTE to tackle the unbalanced dataset problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57968ab",
   "metadata": {},
   "source": [
    "#using SMOTE to balance the dataset creating a subset dataset with target y = 'Incidence' and removing Incidence','MonthsLastRev','InspectionDay','PipeId', 'MaintenanceId', 'InspectionYear', 'InspectionDate',  'Province', 'Town', 'YearBuilt' for x\n",
    "X = df_baseline.drop(['PipeId','Province', 'Town'], axis=1)\n",
    "y = df_baseline['Incidence']\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "X_res.shape,y_res.shape\n",
    "\n",
    "#create a pandas dataframe with the new balanced dataset\n",
    "df_baseline_balanced = pd.DataFrame(X_res, columns=X.columns)\n",
    "df_baseline_balanced['Incidence'] = y_res\n",
    "df_baseline_balanced.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bec3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using SMOTE to balance the dataset creating a subset dataset with target y = 'Incidence'\n",
    "X = df_baseline.drop('Incidence', axis=1)\n",
    "y = df_baseline['Incidence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "#count values for Incidence in y_train\n",
    "y_train.value_counts()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a4bc545",
   "metadata": {},
   "source": [
    "# Baseline approach\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0f2e5a9",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d054e766",
   "metadata": {},
   "source": [
    "# Trying model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest classifier with regularization and gridsearch to find the best parameters for the model\n",
    "rfc = RandomForestClassifier(random_state=42, n_jobs=-1, max_depth = 2, verbose=1, n_estimators=100, max_features='auto', min_samples_leaf=1, min_samples_split=2, class_weight='balanced' )\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "#plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='coolwarm')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22deedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfc.predict_proba(X_test)\n",
    "predictions = predictions[:, 1]\n",
    "\n",
    "#show accuracy score\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use model to predict on test set\n",
    "predictions = rfc.predict_proba(X_test)\n",
    "predictions = predictions[:, 1]\n",
    "\n",
    "#show accuracy score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcad6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Incidence in sample_submission creating a new df called sample_submission2\n",
    "sample_submission2 = sample_submission.drop('Incidence', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ed4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count null in sample_submission\n",
    "sample_submission.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886743c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a022371",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7973ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop incidence in sample_submission\n",
    "sample_submission = sample_submission.drop('Incidence', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions for submission using the model\n",
    "predictions = rfc.predict_proba(sample_submission)\n",
    "predictions = predictions[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cfa498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add predictions to submission\n",
    "sample_submission ['Incidence'] = predictions\n",
    "\n",
    "#show submission\n",
    "sample_submission.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a55fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc1da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all columns except PipeId and Incidence in submission2 creating kaggle_submission\n",
    "kaggle_submission = sample_submission.drop(['Diameter', 'Length', 'Pressure', 'NumConnections', 'aspect',\n",
    "       'Relative_Thickness', 'area_connection', 'gas_natural',\n",
    "       'Material_Acrylonitrile-Butadiene-Styrene', 'Material_Copper',\n",
    "       'Material_Fiberglass-Reinforced Plastic', 'Material_Polyethylene',\n",
    "       'Material_Polypropylene', 'Yearly Sun Hours (hours)',\n",
    "       'Average_MonthsLastRev', 'MonthsLastRev', 'No_Inspections',\n",
    "       'No_Incidences_Total', 'Age_pipe_at_inspection',\n",
    "       'Population density (persons/sqkm)'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d73cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#show kaggle_submission\n",
    "kaggle_submission.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b85cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6372270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export kaggle_submission to csv\n",
    "os.chdir(r\"C:\\Users\\JuanHorrillo\\OneDrive - IE Students\\Documents\\Masters\\Sustainability\\csvs\")\n",
    "\n",
    "kaggle_submission.to_csv('kaggle_submission_new_features_baseline.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418d9eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07dfa46f",
   "metadata": {},
   "source": [
    "# Lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d29fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using lazypredict to  find the best model to predict on the dataset\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "clf = LazyClassifier(verbose=1, ignore_warnings=False, custom_metric=None, predictions=True, random_state=42, n_jobs=-1)\n",
    "models, predictions = clf.fit(X_train, X_train, X_test, y_test)\n",
    "models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e561a8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9efabc23ee1208aa516d94608c8e94efdc40758ec3a749c4f24d7a85602aee77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
